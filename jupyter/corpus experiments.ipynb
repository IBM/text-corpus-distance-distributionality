{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd8fc9f-57f9-4f4a-995b-d417f78ee230",
   "metadata": {},
   "source": [
    "KSC corpora experiments for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffcffac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../src')\n",
    "sys.path.insert(0, '../../meme/src')\n",
    "sys.path.insert(0, '../../comparing-corpora/src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from compcor.text_tokenizer_embedder import STTokenizerEmbedder\n",
    "from compcor.corpus_metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from utils import QUORA, load_paraphrases, common_tokens_matrix, sort_numsuffix\n",
    "from binarize_metrics import *\n",
    "from ksc_methods import plotKSC, runKSC, runKSC_fixed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9fcc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate base samples from QUORA of size subsample_size to ensure that C_A and C_B are paired paraphrases\n",
    "np.random.seed(42)\n",
    "subsample_size = 50\n",
    "nrepetitions = 5 # number of random samplings of entire KSC set\n",
    "\n",
    "res_out_dir = os.path.join(os.getcwd(), 'ksc_results', 'data')\n",
    "fig_out_dir = os.path.join(os.getcwd(), 'ksc_results', 'figures')\n",
    "\n",
    "# generate a single sampling of subsample_size pairs of paraphrases, to use for the KSC corpora\n",
    "corpus1, corpus2 = load_paraphrases(subsample=subsample_size)\n",
    "print(corpus1[:5])\n",
    "print(corpus2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pairs of paraphrases in embedding space\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# embed and do TSNE transformation\n",
    "from sklearn.manifold import TSNE\n",
    "import umap # need to install umap-learn and not umap\n",
    "import matplotlib.pyplot as plt\n",
    "# from mycolorpy import colorlist as mcp\n",
    "# import itertools\n",
    "sentence_transformer_model = \"all-MiniLM-L12-v2\"\n",
    "\n",
    "reducers = {\"TSNE\": TSNE(n_components=2, metric=cosine_arccos_transform), \n",
    "            \"UMAP\": umap.UMAP(metric=cosine_arccos_transform)}\n",
    "\n",
    "# use the same model as the encoder, for consistency\n",
    "def embed_sentences(sentences, normalize=False):\n",
    "    embedder = SentenceTransformer(sentence_transformer_model)\n",
    "    vectors = embedder.encode(sentences, show_progress_bar=True)\n",
    "    return preprocessing.normalize(vectors) if normalize else vectors\n",
    "\n",
    "corpus_embeddings = [embed_sentences(sentences=corp) for corp in [corpus1, corpus2]]\n",
    "projection = {kk: vv.fit_transform(np.vstack(corpus_embeddings))\n",
    "              for kk, vv in reducers.items()}\n",
    "\n",
    "lc = len(corpus1)\n",
    "# after fitting together, then split into two\n",
    "projection = {kk: [vv[:lc, :], vv[lc:, :]] for kk, vv in projection.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documment distances\n",
    "dmat = cosine_arccos_transform(c1=np.vstack(corpus_embeddings)).astype(float)\n",
    "dim = dmat.shape[0]\n",
    "halfdim = int(dim/2)\n",
    "\n",
    "# heatmap\n",
    "fig = plt.imshow(dmat, cmap='hot', vmin=0)\n",
    "ax = plt.gca()\n",
    "ax.set_title('A and B document cosine distances ' + r'$\\delta$')\n",
    "# make grid at half\n",
    "ticks = np.arange(-0.5, dim + 0.5, halfdim)\n",
    "tick_labels = [\"\"] * len(ticks)\n",
    "ax.set_xticks(ticks, labels=tick_labels, minor=False)\n",
    "ax.set_yticks(ticks, labels=tick_labels, minor=False)\n",
    "ax.grid(color='gray', linestyle='-', linewidth=0.5)\n",
    "# labels at minor\n",
    "label_locs = np.array([0.25, 0.75]) * dim\n",
    "labels = [\"A\", \"B\"]\n",
    "ax.set_xticks(label_locs, labels=labels, minor=True)\n",
    "ax.set_yticks(label_locs, labels=labels, minor=True)\n",
    "\t\n",
    "plt.colorbar()\n",
    "plt.savefig(os.path.join(fig_out_dir, 'cosine_distance_mat.pdf'))\n",
    "plt.show()\n",
    "\n",
    "# density plot\n",
    "# distance between each document and itself (0 by definition)\n",
    "equal_distances = np.diag(dmat).astype(float)\n",
    "A_vs_B = dmat[0:halfdim, halfdim:] # upper quadrant\n",
    "paraphrase_distances = np.diag(A_vs_B)  \n",
    "upper_idx = np.triu_indices(n=halfdim, k=1)\n",
    "# take non-identical pairs within A and B, and non-paraphrases between A and B\n",
    "nonparaphrase_distances = np.concatenate((dmat[:halfdim, :halfdim][upper_idx], dmat[halfdim:, halfdim:][upper_idx], A_vs_B[upper_idx]))\n",
    "\n",
    "\n",
    "dist_type = ['paraphrases'] * len(paraphrase_distances) + ['identical'] * len(equal_distances) + ['non-paraphrases'] * len(nonparaphrase_distances)\n",
    "Ddf = pd.DataFrame({\"d\": np.concatenate((paraphrase_distances, equal_distances, nonparaphrase_distances)),\n",
    "                    \"type\": dist_type})\n",
    "# add a small nonzero value so can plot densities\n",
    "Ddf = pd.concat([Ddf, pd.DataFrame({'d': 0.0001, 'type': 'identical'}, index=[len(Ddf)])])\n",
    "\n",
    "\n",
    "g = sns.kdeplot(data=Ddf, x='d', hue='type', common_norm=False, clip=[dmat.min(), dmat.max()], warn_singular=False, legend=False)\n",
    "plotted_lines = g.get_lines()\n",
    "max_dens = max([plotted_lines[ii].get_data()[1].max() for ii in [0,2]]) * 1.025\n",
    "# plt.legend(loc='upper center', fontsize=20)\t\n",
    "# lty = ['dotted', 'solid', 'dashed']\n",
    "# handles = g.legend_.legendHandles[::-1]\n",
    "# for line, lt, handle in zip(g.lines, lty, handles):\n",
    "# \tline.set_linestyle(lt)\n",
    "# \thandle.set_ls(lt)\n",
    "g.set_ylim(top=max_dens)\n",
    "\n",
    "# plt.legend(loc='upper center', fontsize='x-small')\n",
    "# g.legend_.set_font(fontsize='x-small')\n",
    "plt.xticks(fontsize='xx-small')\n",
    "plt.yticks(fontsize='xx-small')\n",
    "g.set_xlabel(xlabel='distance ' + r'$\\delta$', fontsize='xx-small')\n",
    "g.set_ylabel(ylabel='density', fontsize='xx-small')\n",
    "plt.title('Document cosine distances ' + r'$\\delta$', fontsize='small')\n",
    "plt.savefig(os.path.join(fig_out_dir, 'distribution_cosine_distance_mat.pdf'))\n",
    "plt.show()\n",
    "\n",
    "# print(os.path.join(fig_out_dir, 'distribution_cosine_distance_mat.pdf'))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "colors = ['orange', 'blue']\n",
    "\n",
    "for pmethod, proj in projection.items():\n",
    "    for ii, cc in enumerate(proj):\n",
    "        fc = colors[ii] if ii == 0 else 'none'\n",
    "        plt.scatter(cc[:,0], cc[:,1], facecolors=fc, edgecolors=colors[ii], label='corpus {}'.format(ii+1))\n",
    "    for xy0, xy1 in zip(proj[0], proj[1]):\n",
    "        plt.arrow(x=xy0[0], y=xy0[1], dx=xy1[0] - xy0[0], dy=xy1[1] - xy0[1])\n",
    "    plt.legend(fontsize='xx-small')\n",
    "    plt.xticks(fontsize='xx-small')\n",
    "    plt.yticks(fontsize='xx-small')\n",
    "    plt.title('{} projection'.format(pmethod))\n",
    "    plt.savefig(os.path.join(fig_out_dir, '{}_paraphrase_projection.pdf'.format(pmethod)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e445fa7-c92f-4f5a-9e9e-3493c5f421f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate how Directed Average Hausdorff Distance works\n",
    "\n",
    "from illustrate_distributionality import *\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "X0, X1 = gen_data(n_samples=15, draw=False, jitter_std=2.0)\n",
    "X0 = X0.X\n",
    "dmat = euclidean_distances(X=X0, Y=X1)\n",
    "neibs0 = np.argmin(dmat, axis=1) # nearest neighbor of each in X0\n",
    "neibs1 = np.argmin(dmat, axis=0) # nearest neighbor of each in X1\n",
    "dxy0 = X1[neibs0,:] - X0\n",
    "dxy1 = X0[neibs1,:] - X1\n",
    "\n",
    "# average directional distance\n",
    "dxy0_mean = np.sqrt(np.square(dxy0).sum(axis=1)).mean()\n",
    "dxy1_mean = np.sqrt(np.square(dxy1).sum(axis=1)).mean() \n",
    "\n",
    "plt.scatter(X0[:,0], X0[:,1], s=120, facecolors='none', edgecolors='green', label='sample 1', alpha=0.5)\n",
    "plt.scatter(X1[:,0], X1[:,1], s=120, c='green', label='sample 2', alpha=0.5)\n",
    "\n",
    "for xy, dxy in zip(X0, dxy0):\n",
    "\tplt.arrow(x=xy[0], y=xy[1], dx=dxy[0], dy=dxy[1], color='grey', linestyle=\"dotted\", width=0.01, head_width=0.4, length_includes_head=True)\n",
    "plt.arrow(x=xy[0], y=xy[1], dx=dxy[0], dy=dxy[1], color='grey', linestyle=\"dotted\", width=0.01, head_width=0.4, length_includes_head=True, label='neighbor 1->2')\n",
    "for xy, dxy in zip(X1, dxy1):\n",
    "\tplt.arrow(x=xy[0], y=xy[1], dx=dxy[0], dy=dxy[1], color='green', linestyle=\"solid\", width=0.001, head_width=0.4, length_includes_head=True)\n",
    "plt.arrow(x=xy[0], y=xy[1], dx=dxy[0], dy=dxy[1], color='green', linestyle=\"solid\", width=0.001, head_width=0.4, length_includes_head=True, label='neighbor 2->1')\n",
    "\n",
    "\n",
    "plt.title('AHD distance = ({} + {})/2'.format(np.round(dxy0_mean, 2), np.round(dxy1_mean, 2)))\n",
    "plt.legend(fontsize='x-small')\n",
    "\n",
    "# set aspect as equal\n",
    "plt.gca().set_aspect(1.0)\n",
    "plt.savefig(os.path.join(fig_out_dir, 'Directed_Average_Hausdorff.pdf'))\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define more specific metrics\n",
    "# define specific values of k for PR\n",
    "PR1 = lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=1)\n",
    "PR2 = lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=2)\n",
    "PR5 = lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=5)\n",
    "PR10 = lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=10)\n",
    "\n",
    "DC1 = lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=1)\n",
    "DC2 = lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=2)\n",
    "DC5 = lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=5)\n",
    "DC10 = lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=10)\n",
    "\n",
    "# using cosine rather than euclidean\n",
    "PR1_cos =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=1, cosine=True)\n",
    "PR2_cos =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=2, cosine=True)\n",
    "PR3_cos =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=3, cosine=True)\n",
    "PR5_cos =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=5, cosine=True)\n",
    "PR10_cos = lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=10, cosine=True)\n",
    "\n",
    "DC1_cos =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=1, cosine=True)\n",
    "DC2_cos =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=2, cosine=True)\n",
    "DC3_cos =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=3, cosine=True)\n",
    "DC5_cos =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=5, cosine=True)\n",
    "DC10_cos = lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=10, cosine=True)\n",
    "\n",
    "# create list of metrics and names for plotting\n",
    "base_metrics = [fid_distance, mauve_distance, classifier_distance, IRPR_distance,\n",
    "               DC1_cos, DC2_cos, DC3_cos, DC5_cos, DC10_cos, PR1_cos, PR2_cos, PR3_cos, PR5_cos, PR10_cos, Directed_Hausdorff_distance, Energy_distance]\n",
    "base_metrics_names = ['FID', 'MAUVE', 'CLASSIFIER', 'IRPR', 'DC_1','DC_2', 'DC_3','DC_5', 'DC_10', 'PR_1', 'PR_2', 'PR_3', 'PR_5', 'PR_10', 'HAUSDORFF', 'ENERGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c37f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run KSC on original corpora\n",
    "metrics_df, distances_df, _ = runKSC_fixed_sample(base_metrics, metric_names=base_metrics_names, corpus1=corpus1, corpus2=corpus2, repetitions=nrepetitions, n=subsample_size, k=15, coverage=True, output=None)\n",
    "\n",
    "is_baseline = np.isin(distances_df['metric'], ['ENERGY', 'HAUSDORFF'])\n",
    "plotKSC(distances_df.loc[is_baseline], boxplot=True, standardized=True, ncolumns=2, output=fig_out_dir, fname='KSC_standardized_baselines.pdf')\n",
    "plotKSC(distances_df.loc[np.logical_not(is_baseline)], boxplot=True, standardized=True, ncolumns=8, output=fig_out_dir, fname='KSC_standardized_others.pdf')\n",
    "selected = ['FID', 'MAUVE', 'IRPR', 'CLASSIFIER', 'DC_1', 'DC_2', 'DC_5', 'PR_1', 'PR_2', 'PR_5']\n",
    "plotKSC(distances_df.loc[np.isin(distances_df['metric'], selected)], boxplot=True, standardized=True, ncolumns=5, output=fig_out_dir, fname='KSC_standardized_others_subset.pdf')\n",
    "plotKSC(distances_df.loc[np.isin(distances_df['metric'], selected)], boxplot=True, standardized=True, ncolumns=5, output=fig_out_dir, fname='KSC_raw_others_subset.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822745fd-73c7-4660-8ede-e45c369e172d",
   "metadata": {},
   "source": [
    "Now try to group each distance metric $d$ into more/less distributional by how close it is to the baselines ENERGY and HAUSDORFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src')\n",
    "from probability_functions import *\n",
    "from itertools import combinations\n",
    "from ndicts import NestedDict\n",
    "from copy import deepcopy\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from collections import defaultdict, namedtuple\n",
    "from ksc_methods import runKSC_fixed_sample, calcKSC_scores_fixed_sample, get_metric_dependant_data\n",
    "from scipy.stats import anderson_ksamp, cramervonmises_2samp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def est_density(x_true):\n",
    "    # estimate probability of xs\n",
    "    return KDEUnivariate(x_true).fit()\n",
    "\n",
    "def obs2ell_dict(ells, d):\n",
    "    ed = defaultdict(list)\n",
    "    for ell, dd in zip(ells, d):\n",
    "        ed[ell].append(dd)\n",
    "    \n",
    "    ed = {ell: np.array(vv) for ell, vv in ed.items()}    \n",
    "    return ed\n",
    "\n",
    "gof_tests = {'Cramer Von-Mises': lambda x, y: cramervonmises_2samp(x, y).pvalue,\n",
    "             'Anderson-Darling': lambda x, y: anderson_ksamp(samples=[x, y]).pvalue}\n",
    "    \n",
    "inf_clip = 1e50\n",
    "\n",
    "\n",
    "class KSC_probabilities:\n",
    "\n",
    "    EVAL_STD_PTS = np.linspace(start=-8, stop=8, num=3000)\n",
    "    EVAL_STD_DX = EVAL_STD_PTS[1] - EVAL_STD_PTS[0]\n",
    "        \n",
    "    def __init__(self, corpus1, corpus2, nrepetitions=5, k=5):\n",
    "        # check are the same length\n",
    "        if len(corpus1) != len(corpus2):\n",
    "            raise ValueError('corpora must have the same length')\n",
    "        \n",
    "        self.corpus1, self.corpus2 = corpus1, corpus2\n",
    "        self.n = len(self.corpus1)\n",
    "        self.k = max(1, min(self.n, int(k)))\n",
    "        self.nrepetitions = nrepetitions\n",
    "        self.like_res = namedtuple('like_res', 'metric_name full_lv full_decision trunc_lv trunc_decision')\n",
    "\n",
    "        \n",
    "        metrics = [Directed_Hausdorff_distance, Energy_distance]\n",
    "        metrics_names = ['Hausdorff', 'Energy']\n",
    "        \n",
    "        n = max(len(corpus1), len(corpus2))\n",
    "        _, sim_distances, self.ksc_indices = runKSC_fixed_sample(metrics, metric_names=metrics_names,\n",
    "                                                                 corpus1=self.corpus1, corpus2=self.corpus2, \n",
    "                                                                 repetitions=self.nrepetitions, n=self.n, k=self.k,\n",
    "                                                                 coverage=True, output=None)\n",
    "        self.ells = sim_distances['l'].unique().tolist()\n",
    "        # use standardized distances\n",
    "        # pool across repetitions for each ell \n",
    "        self.base_metric_distances = {mn: obs2ell_dict(ells=df['l'], d=df['distance_score'])\n",
    "                                 for mn, df in sim_distances.groupby('metric')}\n",
    "        self.ell_wts = {ell: len(vv) for ell, vv in self.base_metric_distances[metrics_names[0]].items()}\n",
    "        sum_wts = np.sum([vv for vv in self.ell_wts.values()])\n",
    "        # how much to weight each ell's samples\n",
    "        self.ell_wts.update({ell: vv/sum_wts for ell, vv in self.ell_wts.items()})\n",
    "        \n",
    "        self.base_metric_kdes = {mn: {ell: self._est_density(vals) for ell, vals in elldict.items()}\n",
    "                                for mn, elldict in self.base_metric_distances.items()}\n",
    "\n",
    "\n",
    "    def _est_density(self, x_true):\n",
    "        # estimate probability of xs\n",
    "        uv = np.unique(x_true)\n",
    "        if len(uv) == 1:\n",
    "            uv = uv[0]\n",
    "            # add value on either side so bandwidth won't be 0\n",
    "            x_true = np.concatenate((x_true, [uv - KSC_probabilities.EVAL_STD_DX, uv + KSC_probabilities.EVAL_STD_DX]))\n",
    "        return KDEUnivariate(x_true).fit()\n",
    "\n",
    "    \n",
    "    def _loglike(self, densfunc, xs, as_sum=True):\n",
    "        res = np.clip(a=np.log(densfunc.evaluate(xs)), a_min=-1*inf_clip, a_max=inf_clip)        \n",
    "        return res.sum() if as_sum else res\n",
    "\n",
    "\n",
    "    def _squared_discrepancy(self, base_dens_func, test_dens_func):\n",
    "        # Fan 1994 approximate test\n",
    "        return KSC_probabilities.EVAL_STD_DX * np.sum(np.square(base_dens_func.evaluate(KSC_probabilities.EVAL_STD_PTS) - test_dens_func.evaluate(KSC_probabilities.EVAL_STD_PTS)))\n",
    "        \n",
    "    \n",
    "    def calc_metric_distances(self, metric, metric_name):\n",
    "        # test a new metric vs the two baselines\n",
    "        c1 = get_metric_dependant_data(metric, self.corpus1)\n",
    "        c2 = get_metric_dependant_data(metric, self.corpus2)\n",
    "        \n",
    "        distance_dfs = pd.concat([calcKSC_scores_fixed_sample(c1, c2, indices_from_each=ksc_idxs, metric=metric, metric_name=metric_name, rep=ii)[0]\n",
    "                                  for ii, ksc_idxs in enumerate(self.ksc_indices)])\n",
    "        # distance_dfs = pd.DataFrame(distance_dfs, columns=['metric', 'repetition', 'i', 'j', 'l', 'distance', 'distance_score'])\n",
    "        # drop NaN values\n",
    "        distance_dfs.dropna(subset=['distance', 'distance_score'], inplace=True)\n",
    "    \n",
    "        \n",
    "        # combine across repetitions\n",
    "        eval_metric_distances = obs2ell_dict(ells=distance_dfs['l'].astype(int), d=distance_dfs['distance_score'].astype(float))\n",
    "        missing_ells = [ell for ell in eval_metric_distances if ell not in self.ells]\n",
    "        for ell in missing_ells:\n",
    "            eval_metric_distances[ell] = np.array([]).astype(float)\n",
    "        \n",
    "        return eval_metric_distances\n",
    "\n",
    "\n",
    "    def test_new_metric(self, metric, metric_name, alpha=0.05, wtd=True):\n",
    "        metric_distances = self.calc_metric_distances(metric, metric_name)\n",
    "        metric_distances_kdes = {ell: self._est_density(vals) for ell, vals in metric_distances.items()}\n",
    "        \n",
    "        pvalues = {tn: {bmn: np.array([tf(x=metric_distances[ell], y=ellvals) for ell, ellvals in bmvals.items()])\n",
    "                       for bmn, bmvals in self.base_metric_distances.items()}\n",
    "                   for tn, tf in gof_tests.items()}\n",
    "        # use default Holm-Sidak\n",
    "        mult_test_res = {tn: {bmn: multipletests(pvals=bpvals, alpha=alpha, returnsorted=True)\n",
    "                              for bmn, bpvals in tpvals.items()}\n",
    "                         for tn, tpvals in pvalues.items()}\n",
    "\n",
    "        # calculate estimate of sum squared deviation betwen densities (take mean to adjust for number of ells)\n",
    "        fan_test_stat = {bmn: np.mean([(self.ell_wts[ell] if wtd else 1/len(self.ell_wts)) * self._squared_discrepancy(base_dens_func=bmnf, test_dens_func=metric_distances_kdes[ell])\n",
    "                                    for ell, bmnf in bkdefuncs.items()])\n",
    "                         for bmn, bkdefuncs in self.base_metric_kdes.items()}\n",
    "        \n",
    "        return mult_test_res, fan_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d7cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test various metrics against this baseline\n",
    "ksc_tester = KSC_probabilities(corpus1=corpus1, corpus2=corpus2, k=15)\n",
    "\n",
    "# show KDEs of resulting baselines metric distributions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_points = np.linspace(start=-4, stop=3, num=1000)\n",
    "colors = ['red', 'blue']\n",
    "ltys = ['solid', 'dashed']\n",
    "kde_types = list(ksc_tester.base_metric_kdes.keys())\n",
    "\n",
    "fig, axs = plt.subplots(nrows=ksc_tester.k - 1, ncols=1, sharex=True, sharey=False)\n",
    "for ii, ax in enumerate(fig.axes):\n",
    "    for kt, col, lty in zip(kde_types, colors, ltys):\n",
    "        hts = ksc_tester.base_metric_kdes[kt][ii+1].evaluate(eval_points)\n",
    "        ax.plot(eval_points, hts, color=col, linestyle=lty)\n",
    "    ax.axes.yaxis.set_ticklabels([])\n",
    "    # ax.axes.set_ylabel(r'$\\ell={}$'.format(ii+1), rotation=0, fontsize=10)\n",
    "    ax.axes.set_ylabel(ii+1, rotation=0, fontsize=10)\n",
    "    ax.yaxis.set_label_coords(-.03, 0.2)\n",
    "\n",
    "fig.suptitle(\"KDEs \" + r'$\\hat{f}_d^{\\ell}$' + \" of \" + r'$\\tilde{D}^p_{\\ell}(A,B,d)$' + ' vs ' + r'$\\ell$', fontsize=20)\n",
    "fig.supylabel(r'$\\ell$', fontsize=20, rotation=0)\n",
    "plt.savefig(os.path.join(fig_out_dir, 'KSC_baseline_testing_KDEs.pdf'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829aa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform testing on metrics to group them\n",
    "\n",
    "test_results_wtd = [ksc_tester.test_new_metric(metric=mm, metric_name=mn, wtd=True) for mm, mn in zip(base_metrics, base_metrics_names)]\n",
    "test_results_unwtd = [ksc_tester.test_new_metric(metric=mm, metric_name=mn, wtd=False) for mm, mn in zip(base_metrics, base_metrics_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7c5c0-9d5a-4dc0-a584-7a1b2e4c526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the deviations\n",
    "\n",
    "res_dfs = {'weighted': pd.DataFrame([vv[1] for vv in test_results_wtd]),\n",
    "           'unweighted': pd.DataFrame([vv[1] for vv in test_results_unwtd])}\n",
    "\n",
    "\n",
    "for kk, df in res_dfs.items():\n",
    "    df['metric'] = base_metrics_names\n",
    "    df = df.loc[np.logical_not(np.isin(df['metric'], ['HAUSDORFF', 'ENERGY']))]\n",
    "    df = pd.melt(df, id_vars=['metric'], value_vars=['Energy', 'Hausdorff'])\n",
    "    df.rename(columns={'variable': 'type', 'value': 'squared deviation'}, inplace=True)\n",
    "\n",
    "    res_dfs[kk] = df\n",
    "    \n",
    "    g = sns.catplot(data=df, kind=\"bar\",\n",
    "        y=\"metric\", x=\"squared deviation\", hue=\"type\",\n",
    "        palette=\"dark\", alpha=.6, orient='h', height=10, aspect=1)\n",
    "    plt.title(r'Squared deviation of KDEs from baseline, $\\ell$-{}'.format(kk))\n",
    "    plt.savefig(os.path.join(fig_out_dir, 'KDE_deviations_{}.pdf'.format(kk)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927deaf-4a3a-4e2b-89e6-fcaf5ab8223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate effect of components of DC and PR\n",
    "PR1_cos_comp =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=1, components=True, cosine=True)\n",
    "PR2_cos_comp =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=2, components=True, cosine=True)\n",
    "PR3_cos_comp =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=3, components=True, cosine=True)\n",
    "PR5_cos_comp =  lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=5, components=True, cosine=True)\n",
    "PR10_cos_comp = lambda c1, c2: pr_distance(corpus1=c1, corpus2=c2, nearest_k=10, components=True, cosine=True)\n",
    "\n",
    "ks = [1,2,3,5,10]\n",
    "PR_component_metrics = [PR1_cos_comp, PR2_cos_comp, PR3_cos_comp, PR5_cos_comp, PR10_cos_comp]\n",
    "PR_names = ['PR_{}'.format(ii) for ii in ks]\n",
    "\n",
    "DC1_cos_comp =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=1, components=True, cosine=True)\n",
    "DC2_cos_comp =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=2, components=True, cosine=True)\n",
    "DC3_cos_comp =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=3, components=True, cosine=True)\n",
    "DC5_cos_comp =  lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=5, components=True, cosine=True)\n",
    "DC10_cos_comp = lambda c1, c2: dc_distance(corpus1=c1, corpus2=c2, nearest_k=10, components=True, cosine=True)\n",
    "\n",
    "DC_component_metrics = [DC1_cos_comp, DC2_cos_comp, DC3_cos_comp, DC5_cos_comp, DC10_cos_comp]\n",
    "DC_names = ['DC_{}'.format(ii) for ii in ks]\n",
    "\n",
    "_, pr_distances_df, _ = runKSC_fixed_sample(PR_component_metrics, metric_names=PR_names, corpus1=corpus1, corpus2=corpus2, repetitions=1, n=subsample_size, k=15, coverage=True, output=None)\n",
    "tmp = pd.DataFrame(pr_distances_df['distance'].tolist()) # extract the distance \n",
    "pr_distances_df.drop(columns=['distance'], inplace=True)\n",
    "pr_distances_df = pd.concat([pr_distances_df, tmp], axis=1)\n",
    "\n",
    "_, dc_distances_df, _ = runKSC_fixed_sample(DC_component_metrics, metric_names=PR_names, corpus1=corpus1, corpus2=corpus2, repetitions=1, n=subsample_size, k=15, coverage=True, output=None)\n",
    "tmp = pd.DataFrame(dc_distances_df['distance'].tolist()) # extract the distance tuples\n",
    "dc_distances_df.drop(columns=['distance'], inplace=True)\n",
    "dc_distances_df = pd.concat([dc_distances_df, tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02305c77-6882-47bc-9d2a-9ac85aa2d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the components\n",
    "\n",
    "dc_distances_df['k'] = [int(vv.split('_')[1]) for vv in dc_distances_df['metric']]\n",
    "pr_distances_df['k'] = [int(vv.split('_')[1]) for vv in pr_distances_df['metric']]\n",
    "dc_distances_df.rename(columns={'distance_score': 'standardized distance'}, inplace=True)\n",
    "pr_distances_df.rename(columns={'distance_score': 'standardized distance'}, inplace=True)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10 * 3, 8))\n",
    "\n",
    "for ax, vv in zip(fig.axes, ['precision', 'recall', 'standardized distance']):\n",
    "    g = sns.boxplot(x='l', y=vv, data=pr_distances_df, ax=ax, hue='k')\n",
    "    g.set(ylabel=None, xlabel=r'$\\ell$')\n",
    "    ax.set_title(vv, fontdict={'size': 'xx-large'})\n",
    "fig.suptitle('Precision-Recall (PR) by k neighbors', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(fig_out_dir, 'pr_distance_vs_k.pdf'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10 * 3, 8))\n",
    "\n",
    "for ax, vv in zip(fig.axes, ['density', 'coverage', 'standardized distance']):\n",
    "    g = sns.boxplot(x='l', y=vv, data=dc_distances_df, ax=ax, hue='k')\n",
    "    g.set(ylabel=None, xlabel=r'$\\ell$')\n",
    "    ax.set_title(vv, fontdict={'size': 'xx-large'})\n",
    "fig.suptitle('Density-Coverage (DC) by k neighbors', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(fig_out_dir, 'dc_distance_vs_k.pdf'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompCor",
   "language": "python",
   "name": "compcor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
